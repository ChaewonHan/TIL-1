# S3 (Simple Storage Service)
>인터넷 스토리지 서비스. 용량에 관계 없이 파일을 저장할 수 있고 웹(HTTP 프로토콜)에서 파일에 접근할 수 있다.

### 1. 사용 이유
- S3는 저장 용량이 무한대이고 파일 저장에 최적화되어 있다. 용량을 추가하거나 성능을 높이는 작업이 필요없다.
- 비용은 EC2와 EBS로 구축하는 것보다 훨씬 저렴
- S3 자체가 수천 대 이상의 매우 성능이 좋은 웹 서버로 구성되어 있어서 EC2와 EBS로 구축했을 때 처럼 Auto Scaling이나 Load Balancing에 신경쓰지 않아도 된다.
- 동적 웹페이지와 정적 웹페이지가 섞여있을 때 동적 웹페이지만 EC2에서 서비스하고 정적 웹페이지는 S3를 이용하면 성능도 높이고 비용도 절감.
- 웹하드 서비스와 비슷하지만, 별도의 클라이언트 설치나 ActiveX를 통하지 않고 HTTP 프로토콜로 파일 업로드/다운로드 처리
- S3 자체로 정적 웹서비스 가능


### 2. 버킷(Bucket)
  - 한 계정 당 최대 100개의 버킷 사용 가능.
  - 버킷 소유권은 이전할 수 없다.
  - 버킷의 이름은 region에 상관없이 globally unique 해야 한다.
  - S3 데이터 모델은 flat structure라서 버킷에 hierarchie나 folder는 없다.
  - 하지만 keyname prefix (Folder1/Object1)를 사용해서 논리적인 hierarchies를 암시할 수 있다.
  - 버킷 안에 다른 버킷을 둘 수 없다.
  - Path-Style URL에서 버킷 이름은 Region specific endpoint를 사용하지 않는 이상 도메인명에 포함되지 않는다.
  - Virtual Hosted Style URL에서 버킷이름은 URL의 도메인명의 일부가 된다.
  - Virtual hosting은 HTTP Host Header를 사용해서 REST API 콜의 버킷을 address하는 데 사용될 수 있다.

### 3. 객체(Object)
  - Object level storage(not a Block level storage)
  - 객체 하나의 크기는 1Byte ~ 5TB
  - 저장 가능한 객체 갯수 무제한
  - 객체마다 각각의 접근 권한 설정 가능
  - default로 private 이다.
  - 객체 metadata는 객체가 업로드 된 후에는 수정될 수 없고, 복사해서 수정해야 한다.
  - 객체는 Range HTTP header를 이용해서 부분적으로 검색할 수 있다.
  - 객체는 Pre-signed url를 사용해서 다운로드 할 수 있다.
  - 객체의 metadata는 response header에 반환된다.
  - Updating any metadata for an object requires all the metadata fields to be specified again

### 4. 기타
- 사용자 설정 metadata는 반드시 "x-amz-meta"라는 prefix로 시작해야 사용자가 정한 key value pair가 설정된다.
- S3 does not process user-defined metadata
- 내구성이 다른 두 가지 옵션이 있다. 
  - Standard Storage는 중요한 데이터 저장.(내구성 99.999999999%)
  - RRS(Reduced Redundancy Storage)는 데이터 사본의 수를 줄여 비용을 낮춤. 원본에서 다시 생성할 수 있는 데이터 저장에 적함. (내구성 99.99%)
  - 파일을 올리고 나서도 설정할 수 있다.
- Server Side Encryption
  - None과 AES-256 중 선택 가능
  - S3에 데이터를 암호화해서 저장하는 옵션.
  - 복호화는 데이터를 가져올 때 이루어진다.
- S3 자체적으로 Version Control 기능을 내장하고 있다. 파일을 이전 내용으로 되돌리거나 삭제한 파일을 복원할 수 있다.
- 버킷에 저장된 객체의 LifeCycle을 관리할 수 있다.
- 멀티파트 업로드
  - 1 ~ 10000 parts를 지원하고, 각 파트는 5MB~5GB, 마지막 파트는 5MB 이하로도 가능하다.
  - 최대 업로드 사이즈는 5TB
  
### 5. 비용
- S3의 비용은 Region에 따라 다르다.
- Storage - GB/month
- Requests - per Request. Request Type(GET, PUT)에 따라 다르다.
- Data Transfer
  - Transfer in - free
  - Transfer out - GB/month (같은 region이나 CloudFront로 이전 제외)
  
### 6. 더 자세한 학습
- [S3 Consistency Model](http://jayendrapatil.com/aws-s3-data-consistency-model/)
- [S3 Subresources](http://jayendrapatil.com/aws-s3-subresources/)
- [S3 Storage Tiers](http://jayendrapatil.com/aws-s3-storage-classes/)
- [S3 Object Versioning](http://jayendrapatil.com/aws-s3-object-versioning/)
- [S3 Lifecycle Management](http://jayendrapatil.com/aws-s3-object-lifecycle-management/)
- [S3 Permission](http://jayendrapatil.com/aws-s3-permisions/)
- [S3 Data Protection](http://jayendrapatil.com/aws-s3-data-protection/)
- [S3 Best Practices](http://jayendrapatil.com/aws-s3-best-practices/)

## *어려운 문제들
1. What are characteristics of Amazon S3? Choose 2 answers  
    a. `Objects are directly accessible via a URL`  
    b. S3 should be used to host a relational database  
    c. S3 allows you to store objects or virtually unlimited size  
    d. `S3 allows you to store virtually unlimited amounts of data` 
    e. S3 offers Provisioned IOPS

2. You are building an automated transcription service in which Amazon EC2 worker instances process an uploaded audio file and generate a text file. You must store both of these files in the same durable storage until the text file is retrieved. You do not know what the storage capacity requirements are. Which storage option is both cost-efficient and scalable?  
    a. Multiple Amazon EBS volume with snapshots  
    b. A single Amazon Glacier vault  
    c. `A single Amazon S3 bucket`  
    d. Multiple instance stores

3. A media company produces new video files on-premises every day with a total size of around 100GB after compression. All files have a size of 1-2 GB and need to be uploaded to Amazon S3 every night in a fixed time window between 3am and 5am. Current upload takes almost 3 hours, although less than half of the available bandwidth is used. What step(s) would ensure that the file uploads are able to complete in the allotted time window?  
    a. Increase your network bandwidth to provide faster throughput to S3  
    b. `Upload the files in parallel to S3 using mulipart upload`  
    c. Pack all files into a single archive, upload it to S3, then extract the files in AWS  
    d. Use AWS Import/Export to transfer the video files  

4. A company is deploying a two-tier, highly available web application to AWS. Which service provides durable storage for static content while utilizing lower Overall CPU resources for the web tier?  
    a. Amazon EBS volume  
    b. `Amazon S3`  
    c. Amazon EC2 instance store  
    d. Amazon RDS instance

5. When you put objects in Amazon S3, what is the indication that an object was successfully stored?  
    a. Each S3 account has a special bucket named_s3_logs. Success codes are written to this bucket with a timestamp and checksum.  
    b. A success code is inserted into the S3 object metadata.  
    c. `A HTTP 200 result code and MD5 checksum, taken together, indicate that the operation was successful.`  
    d. Amazon S3 is engineered for 99.999999999% durability. Therefore there is no need to confirm that data was inserted.

6. You have private video content in S3 that you want to serve to subscribed users on the Internet. User IDs, credentials, and subscriptions are stored in an Amazon RDS database. Which configuration will allow you to securely serve private content to your users?  
    a. `Generate pre-signed URLs for each user as they request access to protected S3 content`  
    b. Create an IAM user for each subscribed user and assign the GetObject permission to each IAM user  
    c. Create an S3 bucket policy that limits access to your private content to only your subscribed users’ credentials  
    d. Create a CloudFront Origin Identity user for your subscribed users and assign the GetObject permission to this user

7. You run an ad-supported photo sharing website using S3 to serve photos to visitors of your site. At some point you find out that other sites have been linking to the photos on your site, causing loss to your business. What is an effective method to mitigate this?  
    a. `Remove public read access and use signed URLs with expiry dates.`  
    b. Use CloudFront distributions for static content.  
    c. Block the IPs of the offending websites in Security Groups.  
    d. Store photos on an EBS volume of the web server.

8. You are designing a web application that stores static assets in an Amazon Simple Storage Service (S3) bucket. You expect this bucket to immediately receive over 150 PUT requests per second. What should you do to ensure optimal performance?  
    a. Use multi-part upload.  
    b. `Add a random prefix to the key names.`  
    c. Amazon S3 will automatically manage performance at this scale.  
    d. Use a predictable naming scheme, such as sequential numbers or date time sequences, in the key names

9. What is the maximum number of S3 buckets available per AWS Account?  
    a. 100 Per region  
    b. There is no Limit  
    c. `100 Per Account (Refer documentation)`  
    d. 500 Per Account  
    e. 100 Per IAM User
  
10. Your customer needs to create an application to allow contractors to upload videos to Amazon Simple Storage Service (S3) so they can be transcoded into a different format. She creates AWS Identity and Access Management (IAM) users for her application developers, and in just one week, they have the application hosted on a fleet of Amazon Elastic Compute Cloud (EC2) instances. The attached IAM role is assigned to the instances. As expected, a contractor who authenticates to the application is given a pre-signed URL that points to the location for video upload. However, contractors are reporting that they cannot upload their videos. Which of the following are valid reasons for this behavior? Choose 2 answers { “Version”: “2012-10-17”, “Statement”: [ { “Effect”: “Allow”, “Action”: “s3:*”, “Resource”: “*” } ] }  
    a. The IAM role does not explicitly grant permission to upload the object. (오답체크: The role has all permissions for all activities on S3)  
    b. The contractorsˈ accounts have not been granted “write” access to the S3 bucket. (오답체크: using pre-signed urls the contractors account don’t need to have access but only the creator of the pre-signed urls)  
    c. `The application is not using valid security credentials to generate the pre-signed URL.`  
    d. The developers do not have access to upload objects to the S3 bucket. (오답체크: developers are not uploading the objects but its using pre-signed urls)  
    e. The S3 bucket still has the associated default permissions. (오답체크: does not matter as long as the user has permission to upload)  
    f. `The pre-signed URL has expired.`

## *Reference
- [아마존 웹 서비스를 다루는 기술 11장 - HTTP 프로토콜과 연동되는 스토리지 S3](http://pyrasis.com/book/TheArtOfAmazonWebServices/Chapter11)
- [Jayendra's Blog - S3 Overview](http://jayendrapatil.com/aws-simple-storage-service-s3-overview/)
